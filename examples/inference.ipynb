{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример инференса модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alcatraz/Documents/PycharmProjects/bubbles_champagne/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src.model import VideoClassifier\n",
    "from src.utils.preprocess import preprocess_data, load_label_encoder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка модели и LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoder loaded from ../checkpoints/task_1_encoder.pkl\n",
      "Model and LabelEncoder loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Укажите путь к сохраненной модели и LabelEncoder\n",
    "model_path = '../checkpoints/trained_model_task0.pkl.zip'  \n",
    "encoder_path = '../checkpoints/task_1_encoder.pkl'\n",
    "\n",
    "model = VideoClassifier()\n",
    "model.load_model(model_path)\n",
    "\n",
    "label_encoder = load_label_encoder(encoder_path)\n",
    "\n",
    "print(\"Model and LabelEncoder loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример путей к тестовым изображениям\n",
    "test_paths = [\n",
    "    '/home/alcatraz/Documents/PycharmProjects/bubbles_champagne/frames/test/pink_glass_0_min/pink0-5_00000.jpg',\n",
    "    '/home/alcatraz/Documents/PycharmProjects/bubbles_champagne/frames/test/pink_glass_0_min/pink0-5_00010.jpg',\n",
    "    '/home/alcatraz/Documents/PycharmProjects/bubbles_champagne/frames/test/pink_glass_0_min/pink0-5_00060.jpg'\n",
    "]\n",
    "\n",
    "# Укажите индекс лейбла, который нужно предсказывать\n",
    "label_index = 0  # Например, выбираем второй лейбл (label2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных и инференс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 3/3 [00:00<00:00, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1]\n",
      "['pink']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(label_encoder\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m---> 10\u001b[0m decoded_labels \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(test_paths, decoded_labels):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> Predicted Label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/PycharmProjects/bubbles_champagne/venv/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:160\u001b[0m, in \u001b[0;36mLabelEncoder.inverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    158\u001b[0m diff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msetdiff1d(y, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)))\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(diff):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(diff))\n\u001b[1;32m    161\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[y]\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [1]"
     ]
    }
   ],
   "source": [
    "X_test, y_test, _ = preprocess_data(test_paths, label_index, label_encoder=label_encoder)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test).to(device)\n",
    "\n",
    "y_pred = model.predict(X_test_tensor)\n",
    "\n",
    "print(y_pred)\n",
    "print(label_encoder.classes_)\n",
    "\n",
    "decoded_labels = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "for path, label in zip(test_paths, decoded_labels):\n",
    "    print(f\"Image: {path} -> Predicted Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
