# Запуск обучения

## Обучение для задачи классификации шампанского:
Пример использования:

Запуск только первой задачи:
```
python tools/train_model_champagne_3tasks.py --train_dir weights/train --val_dir weights/val --output_dir weights --task task1
```

Запуск всех задач:
```
python tools/train_model_champagne_3tasks.py --train_dir weights/train --val_dir weights/val --output_dir weights --task task1 task2 task3
```

Вот подробное описание всех аргументов, которые используются в скрипте. Это можно использовать как инструкцию по запуску и настройке модели:

### Основные аргументы:

1. **`--train_dir` (str, обязательный)**:
   - **Описание**: Указывает путь к директории с тренировочными изображениями (или файлами).
   - **Формат**: В директории должны находиться папки с именами классов, а в них — файлы изображений.
   - **Пример использования**: 
     ```bash
     --train_dir /path/to/train
     ```
   - **Пример структуры директорий**:
     ```
     /path/to/train/
        ├── class1/
        │   ├── image1.jpg
        │   ├── image2.jpg
        ├── class2/
        │   ├── image3.jpg
        │   ├── image4.jpg
     ```

2. **`--val_dir` (str, обязательный)**:
   - **Описание**: Указывает путь к директории с валидационными изображениями (или файлами), аналогично `--train_dir`.
   - **Пример использования**:
     ```bash
     --val_dir /path/to/val
     ```
   - **Пример структуры директорий**:
     ```
     /path/to/val/
        ├── class1/
        │   ├── image1.jpg
        │   ├── image2.jpg
        ├── class2/
        │   ├── image3.jpg
        │   ├── image4.jpg
     ```

3. **`--output_dir` (str, обязательный)**:
   - **Описание**: Указывает путь, куда будут сохранены обученные модели и другие результаты (например, эмбеддинги).
   - **Пример использования**:
     ```bash
     --output_dir /path/to/output
     ```
   - **Что сохраняется**: Модели для каждой задачи (`task1_model`, `task2_model`, `task3_model`), а также эмбеддинги в формате `.pkl`.

---

### Аргумент выбора задач:

4. **`--task` (str, обязательный, один или несколько)**:
   - **Описание**: Позволяет выбрать одну или несколько задач, которые необходимо запустить. Выбор осуществляется из следующих вариантов:
     - `task1`: Первая задача (например, классификация по первому признаку).
     - `task2`: Вторая задача (например, классификация по второму признаку).
     - `task3`: Третья задача (например, классификация по третьему признаку).
   - **Формат**: Может принимать одну или несколько задач, указанных через пробел.
   - **Пример использования**:
     - Для запуска одной задачи:
       ```bash
       --task task1
       ```
     - Для запуска нескольких задач:
       ```bash
       --task task1 task2
       ```

---

### Аргументы предобучения модели (TabNet Pretraining):

5. **`--pretrain_ratio` (float, необязательный, по умолчанию `0.8`)**:
   - **Описание**: Задает долю данных, используемых для предобучения модели.
   - **Пример использования**:
     ```bash
     --pretrain_ratio 0.8
     ```
   - **Значение по умолчанию**: `0.8` означает, что 80% данных будет использоваться для предобучения, а 20% — для оценки на валидации.

6. **`--pretrain_lr` (float, необязательный, по умолчанию `2e-2`)**:
   - **Описание**: Задает скорость обучения для предобучения модели.
   - **Пример использования**:
     ```bash
     --pretrain_lr 0.02
     ```

7. **`--pretrain_mask_type` (str, необязательный, по умолчанию `"entmax"`)**:
   - **Описание**: Тип маски для предобучения. Допустимые значения — `"entmax"` или `"sparsemax"`.
   - **Пример использования**:
     ```bash
     --pretrain_mask_type entmax
     ```

8. **`--pretrain_verbose` (int, необязательный, по умолчанию `10`)**:
   - **Описание**: Задает уровень детализации вывода для предобучения. Чем больше значение, тем больше будет информации в ходе обучения.
   - **Пример использования**:
     ```bash
     --pretrain_verbose 10
     ```

---

### Гиперпараметры для обучения модели TabNet:

9. **`--n_d` (int, необязательный, по умолчанию `64`)**:
   - **Описание**: Количество признаков для слоев принятия решений (decision layers).
   - **Пример использования**:
     ```bash
     --n_d 64
     ```

10. **`--n_a` (int, необязательный, по умолчанию `64`)**:
    - **Описание**: Количество признаков для слоев внимания (attention layers).
    - **Пример использования**:
      ```bash
      --n_a 64
      ```

11. **`--n_steps` (int, необязательный, по умолчанию `5`)**:
    - **Описание**: Количество шагов принятия решений в модели TabNet.
    - **Пример использования**:
      ```bash
      --n_steps 5
      ```

12. **`--gamma` (float, необязательный, по умолчанию `1.5`)**:
    - **Описание**: Значение гамма для управления влиянием прошлых шагов на текущий шаг.
    - **Пример использования**:
      ```bash
      --gamma 1.5
      ```

13. **`--lambda_sparse` (float, необязательный, по умолчанию `1e-4`)**:
    - **Описание**: Параметр регуляризации, влияющий на разреженность представлений.
    - **Пример использования**:
      ```bash
      --lambda_sparse 1e-4
      ```

---

### Параметры оптимизатора и обучения:

14. **`--lr` (float, необязательный, по умолчанию `2e-2`)**:
    - **Описание**: Скорость обучения для оптимизатора.
    - **Пример использования**:
      ```bash
      --lr 0.02
      ```

15. **`--step_size` (int, необязательный, по умолчанию `10`)**:
    - **Описание**: Шаг для уменьшения скорости обучения.
    - **Пример использования**:
      ```bash
      --step_size 10
      ```

16. **`--gamma_lr` (float, необязательный, по умолчанию `0.9`)**:
    - **Описание**: Параметр для уменьшения скорости обучения (коэффициент `gamma` для `StepLR`).
    - **Пример использования**:
      ```bash
      --gamma_lr 0.9
      ```

17. **`--patience` (int, необязательный, по умолчанию `30`)**:
    - **Описание**: Количество эпох, в течение которых обучение продолжается без улучшений, до остановки.
    - **Пример использования**:
      ```bash
      --patience 30
      ```

---

### Аргументы для управления размерами батчей:

18. **`--batch_size` (int, необязательный, по умолчанию `128`)**:
    - **Описание**: Размер батча для обучения.
    - **Пример использования**:
      ```bash
      --batch_size 128
      ```

19. **`--virtual_batch_size` (int, необязательный, по умолчанию `256`)**:
    - **Описание**: Виртуальный размер батча для TabNet, используется для обработки больших наборов данных.
    - **Пример использования**:
      ```bash
      --virtual_batch_size 256
      ```

---

### Прочие параметры:

20. **`--verbose` (int, необязательный, по умолчанию `10`)**:
    - **Описание**: Уровень детализации вывода для процесса обучения. Чем выше значение, тем больше выводится информации.
    - **Пример использования**:
      ```bash
      --verbose 10
      ```

---

### Пример вызова:

Запуск предобучения и всех задач с измененными гиперпараметрами:

```
python tools/train_model_champagne_3tasks.py --train_dir /path/to/train --val_dir /path/to/val --output_dir /path/to/output \
                 --task task1 task2 task3 \
                 --pretrain_ratio 0.9 --pretrain_lr 0.01 --pretrain_mask_type entmax \
                 --n_d 128 --n_a 128 --n_steps 7 --gamma 2.0 --lambda_sparse 1e-3 \
                 --lr 0.01 --step_size 5 --gamma_lr 0.8 --patience 50 \
                 --batch_size 64 --virtual_batch_size 128 --verbose 20
```

Этот вызов запускает обучение модели с конкретными гиперпараметрами для всех трех задач. Вы можете гибко управлять процессом обучения и предобучения с помощью этих аргументов.
